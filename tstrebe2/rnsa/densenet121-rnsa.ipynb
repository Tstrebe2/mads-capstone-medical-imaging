{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30b25f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# Use this block to download extra dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53728e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import pydicom as dicom\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "import rnsa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d16bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cbc03d5-0bd0-4c6d-8f05-efdd7bce2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = '/home/tstrebel/models/rnsa-densenet.pt'\n",
    "train_img_dir = '/home/tstrebel/assets/rnsa-pneumonia/train-images'\n",
    "annotations_file_path = '/home/tstrebel/assets/rnsa-pneumonia/stage_2_train_labels.csv.zip'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83db2f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 21,347 - validate 3,202 - test 2,135\n"
     ]
    }
   ],
   "source": [
    "label_df = pd.read_csv(annotations_file_path).groupby('patientId').first().reset_index()\n",
    "\n",
    "X_train, X_test = train_test_split(label_df, test_size=.2, stratify=label_df.Target, random_state=99)\n",
    "X_val, X_test, = train_test_split(X_test, test_size=.4, stratify=X_test.Target, random_state=99)\n",
    "train_ix, val_ix, test_ix = X_train.index.tolist(), X_val.index.tolist(), (X_test.index.tolist())\n",
    "del(X_train)\n",
    "del(X_val)\n",
    "del(X_test)\n",
    "print('train {:,} - validate {:,} - test {:,}'.format(len(train_ix), len(val_ix), len(test_ix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9acdb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.5]\n",
    "std = [0.225]\n",
    "\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    # torchvision.transforms.RandomRotation((-5, 5)),\n",
    "    torchvision.transforms.Resize(512),\n",
    "    torchvision.transforms.CenterCrop(448),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(512),\n",
    "    torchvision.transforms.CenterCrop(448),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "label_transform = torchvision.transforms.Compose([\n",
    "    partial(torch.tensor, dtype=torch.float),\n",
    "    partial(torch.unsqueeze, dim=0),\n",
    "])\n",
    "    \n",
    "train_dataset = rnsa.RNSADataset(train_img_dir, annotations_file_path, train_ix, train_transform, label_transform)\n",
    "val_dataset = rnsa.RNSADataset(train_img_dir, annotations_file_path, val_ix, val_transform, label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e19f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnsa.Densenet121(torchvision.models.densenet121(weights='DEFAULT'))\n",
    "# model = torch.load(model_save_path)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=1e-3, momentum=.9, weight_decay=1e-4)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "lr_scheduler = rnsa.LRScheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9584c81d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10\n",
      "----------\n",
      "train Loss: \t0.5230 Acc: 0.7394 LR: 0.001000 Time elapsed: 5m 50s\n",
      "validation Loss: 0.4631 Acc: 0.7833 LR: 0.001000 Time elapsed: 6m 46s\n",
      "epoch 2/10\n",
      "----------\n",
      "train Loss: \t0.4864 Acc: 0.7672 LR: 0.001000 Time elapsed: 12m 34s\n",
      "validation Loss: 0.4523 Acc: 0.7811 LR: 0.001000 Time elapsed: 13m 23s\n",
      "epoch 3/10\n",
      "----------\n",
      "train Loss: \t0.4758 Acc: 0.7728 LR: 0.001000 Time elapsed: 19m 13s\n",
      "validation Loss: 0.4518 Acc: 0.7848 LR: 0.001000 Time elapsed: 20m 2s\n",
      "epoch 4/10\n",
      "----------\n",
      "train Loss: \t0.4690 Acc: 0.7756 LR: 0.001000 Time elapsed: 25m 53s\n",
      "validation Loss: 0.4692 Acc: 0.7814 LR: 0.001000 Time elapsed: 26m 44s\n",
      "epoch 5/10\n",
      "----------\n",
      "train Loss: \t0.4646 Acc: 0.7802 LR: 0.001000 Time elapsed: 32m 31s\n",
      "validation Loss: 0.4381 Acc: 0.7936 LR: 0.001000 Time elapsed: 33m 20s\n",
      "epoch 6/10\n",
      "----------\n",
      "train Loss: \t0.4636 Acc: 0.7813 LR: 0.001000 Time elapsed: 39m 14s\n",
      "validation Loss: 0.4597 Acc: 0.7720 LR: 0.001000 Time elapsed: 40m 3s\n",
      "epoch 7/10\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "rnsa.train_model(model,  \n",
    "                 model_save_path,\n",
    "                 train_dataset, \n",
    "                 val_dataset,\n",
    "                 optimizer, \n",
    "                 criterion, \n",
    "                 batch_size=32,\n",
    "                 num_epochs=10\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, best_loss, best_acc = rnsa.load_checkpoint(model_save_path, device)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    if not param.requires_grad:\n",
    "        param.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=.9, weight_decay=1e-4)\n",
    "lr_scheduler = rnsa.LRScheduler(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c78e81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnsa.train_model(model,  \n",
    "                 model_save_path,\n",
    "                 train_dataset, \n",
    "                 val_dataset,\n",
    "                 optimizer, \n",
    "                 criterion, \n",
    "                 batch_size=32,\n",
    "                 num_epochs=10,\n",
    "                 init_best_loss=best_loss\n",
    "                 init_best_acc=best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efe5bd7-7e4f-4aac-bedd-3032ee37eea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = rnsa.RNSADataset(train_img_dir, annotations_file_path, test_ix, train_transform, label_transform)\n",
    "test_data_loader = rnsa.get_data_loader(test_dataset, batch_size=32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    running_targets = torch.Tensor(0, 1).to(device)\n",
    "    running_outputs = torch.Tensor(0, 1).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    for inputs, targets in test_data_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        running_targets = torch.vstack((running_targets, targets))\n",
    "        running_outputs = torch.vstack((running_outputs, outputs)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534296f5-c55f-4a94-be81-fd2e5b1f2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = running_targets.cpu().numpy()\n",
    "y_proba = torch.nn.Sigmoid()(running_outputs).cpu().numpy()\n",
    "\n",
    "precision, recall, thresholds = metrics.precision_recall_curve(y_true, y_proba)\n",
    "f1_scores = (2 * precision * recall) / (precision + recall)\n",
    "ix = np.argmax(f1_scores)\n",
    "best_thresh = thresholds[ix]\n",
    "\n",
    "y_pred = y_proba >= best_thresh #running_outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "precision = metrics.precision_score(y_true, y_pred)\n",
    "recall = metrics.recall_score(y_true, y_pred)\n",
    "f1 = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "print('best threshold\\t{:.4f}'.format(best_thresh))\n",
    "print('precision:\\t{:.4f}'.format(precision))\n",
    "print('recall:\\t\\t{:.4f}'.format(recall))\n",
    "print('f1:\\t\\t{:.4f}'.format(f1))\n",
    "print()\n",
    "\n",
    "fig = plt.figure(dpi=75)\n",
    "ax = plt.gca()\n",
    "sns.heatmap(metrics.confusion_matrix(y_true, y_pred), annot=True, fmt=',', cmap='Blues')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
