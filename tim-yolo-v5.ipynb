{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNoMzJ1Mvof+WehDqvopCwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tstrebe2/umich-mads-capstone-project/blob/main/tim-yolo-v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sa1ttMoqjwKS",
        "outputId": "c55a97d3-9c7c-4e01-c457-2e959f2cfafb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.0 MB 5.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "!{sys.executable} -m pip install pydicom -q\n",
        "!{sys.executable} -mpip install -qr https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt -q  # Yolo Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OF9dE7XNj-gI",
        "outputId": "9874bf38-96e3-479a-c566-2c2d85d66a6a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/capstone/assets/stage_2_train_images.zip'\n",
        "\n",
        "!unzip -qq {path}"
      ],
      "metadata": {
        "id": "lef2dye8j-tP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.optim import SGD\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "\n",
        "import pydicom as dicom\n",
        "from PIL import Image\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "metadata": {
        "id": "BNcuGqBfkC6j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.expand_dims(np.array([[1, 2], [1, 2]]), axis=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur0aXCSFziMC",
        "outputId": "479168ce-501a-4f9d-b6fc-741d7b1daacf"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "  def __init__(self, annotations_file, img_dir, indices=None, transform=None, target_transform=None):\n",
        "    if indices:\n",
        "      self.img_labels = pd.read_csv(annotations_file).iloc[indices].fillna(0)\n",
        "    else:\n",
        "      self.img_labels = pd.read_csv(annotations_file).fillna(0)\n",
        "\n",
        "    self.img_dir = img_dir\n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.img_labels)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img_path = ''.join([os.path.join(self.img_dir, self.img_labels.iloc[idx, 0]), '.dcm'])\n",
        "    \n",
        "    image = dicom.dcmread(img_path)\n",
        "    image = image.pixel_array\n",
        "    # image = Image.fromarray(image.pixel_array)#.convert(mode='RGB')\n",
        "\n",
        "    target = self.img_labels.iloc[idx, 1:-1].values.astype(np.float32)\n",
        "\n",
        "    if self.transform:\n",
        "        image = self.transform(image)\n",
        "    if self.target_transform:\n",
        "        target = self.target_transform(target)\n",
        "    return image, target\n",
        "\n",
        "  def get_classes(self):\n",
        "    return self.img_labels.iloc[:, -1].unique()\n",
        "\n",
        "  classes = property(get_classes)"
      ],
      "metadata": {
        "id": "dq7SXI_zllS_"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotations_file = '/content/drive/MyDrive/capstone/assets/stage_2_train_labels.csv.zip'\n",
        "img_dir = '/content'\n",
        "\n",
        "label_df = pd.read_csv(annotations_file)\n",
        "\n",
        "X_train, X_test = train_test_split(label_df, test_size=.2, stratify=label_df.Target, random_state=99)\n",
        "X_val, X_test, = train_test_split(X_test, test_size=.5, stratify=X_test.Target, random_state=99)\n",
        "X_train, X_val, X_test = X_train.index.tolist(), X_val.index.tolist(), (X_test.index.tolist())\n",
        "\n",
        "len(X_train), len(X_val),  len(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDkN8AxRloiD",
        "outputId": "df7972da-223e-47c1-cb91-0737312fad1d"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(24181, 3023, 3023)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean = 0.46199\n",
        "std = 0.23566\n",
        "\n",
        "transforms = dict(\n",
        "  train = torchvision.transforms.Compose([\n",
        "      # torchvision.transforms.Resize(256),\n",
        "      # torchvision.transforms.CenterCrop(224),\n",
        "      # torchvision.transforms.RandomHorizontalFlip(.2),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean, std),\n",
        "  ]),\n",
        "  val = torchvision.transforms.Compose([\n",
        "      # torchvision.transforms.Resize(256),\n",
        "      # torchvision.transforms.CenterCrop(224),\n",
        "      torchvision.transforms.ToTensor(),\n",
        "      torchvision.transforms.Normalize(mean, std),\n",
        "  ])\n",
        ")\n",
        "\n",
        "datasets = dict(\n",
        "    train=CustomImageDataset(annotations_file, img_dir, indices=X_train, transform=transforms['train'], target_transform=torch.from_numpy),\n",
        "    val=CustomImageDataset(annotations_file, img_dir, indices=X_val, transform=transforms['val'], target_transform=torch.from_numpy),\n",
        "    test=CustomImageDataset(annotations_file, img_dir, indices=X_test, transform=transforms['val'], target_transform=torch.from_numpy),\n",
        ")"
      ],
      "metadata": {
        "id": "xWJx74RslquG"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "data_loaders = dict(\n",
        "    train=DataLoader(datasets['train'], batch_size=batch_size, shuffle=True),\n",
        "    val=DataLoader(datasets['val'], batch_size=batch_size, shuffle=True),\n",
        "    test=DataLoader(datasets['test'], batch_size=batch_size),\n",
        ")\n",
        "\n",
        "dataset_sizes = {x:len(datasets[x]) for x in ('train', 'val', 'test')}\n",
        "\n",
        "print('training steps per epoch:', dataset_sizes['train']//batch_size)\n",
        "print('validation steps per epoch:', dataset_sizes['val']//batch_size)\n",
        "print('test steps per epoch:', dataset_sizes['test']//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m4crNi3lsbW",
        "outputId": "d3cf9ee2-2c50-45d3-913f-dc6144812eaf"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training steps per epoch: 755\n",
            "validation steps per epoch: 94\n",
            "test steps per epoch: 94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uncomment and run to get mean and standard deviation\n",
        "# for x, y in data_loaders['train']:\n",
        "#   break\n",
        "\n",
        "# x.mean(), x.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg9guV8CyssZ",
        "outputId": "135953d6-4bfe-4b69-960d-00c653818576"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.48354), tensor(0.25067))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True, channels=1)\n",
        "model = model.cuda()"
      ],
      "metadata": {
        "id": "16IcIuRVk4Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(g[2], lr=1e-3, momentum=0.9, nesterov=True)\n",
        "loss = torch.nn.\n",
        "\n",
        "for (inputs, targets) in data_loaders['train']:\n",
        "  inputs = inputs.cuda()\n",
        "  targets = targets.cuda()\n",
        "  break\n",
        "\n",
        "with torch.set_grad_enabled(True):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  outputs = model(inputs)\n",
        "\n",
        "outputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6idNUPYak7_K",
        "outputId": "5b000714-2464-4be1-98a0-480b6a7f0946"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 64512, 85])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    }
  ]
}